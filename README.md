# NLP Ã–devi: Haber BaÅŸlÄ±klarÄ±ndan Otomatik Ã–zetleme

Bu proje, CNN/DailyMail veri seti kullanÄ±larak haber makalelerinden otomatik Ã¶zet Ã§Ä±karma iÅŸlemini gerÃ§ekleÅŸtiren bir NLP (DoÄŸal Dil Ä°ÅŸleme) uygulamasÄ±dÄ±r.

## ğŸ“‹ Proje Ã–zeti

Bu proje, T5 (Text-to-Text Transfer Transformer) modelini kullanarak haber makalelerinden otomatik Ã¶zet Ã§Ä±karma gÃ¶revini gerÃ§ekleÅŸtirir. Model, CNN/DailyMail veri setindeki makaleleri ve bunlarÄ±n Ã¶zetlerini kullanarak eÄŸitilmiÅŸtir.

## ğŸ¯ Hedefler

- Haber makalelerinden otomatik Ã¶zet Ã§Ä±karma
- T5 modelinin performansÄ±nÄ± deÄŸerlendirme
- ROUGE metrikleri ile Ã¶zet kalitesini Ã¶lÃ§me
- TÃ¼rkÃ§e dokÃ¼mantasyon ile proje aÃ§Ä±klamasÄ±

## ğŸ“Š SonuÃ§lar

### Model PerformansÄ±
Model eÄŸitimi tamamlandÄ±ktan sonra elde edilen ROUGE skorlarÄ±:

- **ROUGE-1**: 0.3224
- **ROUGE-2**: 0.0715  
- **ROUGE-L**: 0.2239

Bu skorlar, modelin Ã¶zetleme gÃ¶revinde makul bir performans gÃ¶sterdiÄŸini iÅŸaret etmektedir.

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
NLP_Ã¶devi/
â”œâ”€â”€ main.py                 # Ana Ã§alÄ±ÅŸtÄ±rma dosyasÄ±
â”œâ”€â”€ preprocess_data.py      # Veri Ã¶n iÅŸleme fonksiyonlarÄ±
â”œâ”€â”€ train_and_evaluate.py   # Model eÄŸitimi ve deÄŸerlendirme
â”œâ”€â”€ requirements.txt        # Gerekli kÃ¼tÃ¼phaneler
â”œâ”€â”€ evaluation_results.json # DeÄŸerlendirme sonuÃ§larÄ±
â””â”€â”€ README.md              # Bu dosya
```

## ğŸ”§ KullanÄ±lan Teknolojiler

- **Python 3.x**
- **PyTorch**: Derin Ã¶ÄŸrenme framework'Ã¼
- **Transformers**: Hugging Face transformers kÃ¼tÃ¼phanesi
- **T5-small**: Ã–zetleme iÃ§in kullanÄ±lan model
- **ROUGE**: Ã–zet kalitesi deÄŸerlendirme metriÄŸi
- **Datasets**: Hugging Face datasets kÃ¼tÃ¼phanesi

## ğŸ“¦ Kurulum

1. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:
```bash
pip install -r requirements.txt
```

2. Projeyi Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
python main.py
```

## ğŸ”„ Ã‡alÄ±ÅŸma SÃ¼reci

### 1. Veri YÃ¼kleme
- CNN/DailyMail veri seti (3.0.0 versiyonu) yÃ¼klenir
- Train, validation ve test setleri ayrÄ±lÄ±r

### 2. Model HazÄ±rlÄ±ÄŸÄ±
- T5-small modeli ve tokenizer yÃ¼klenir
- Model parametreleri ayarlanÄ±r

### 3. Veri Ã–n Ä°ÅŸleme
- Metinler temizlenir (kÃ¼Ã§Ã¼k harf, noktalama iÅŸaretleri kaldÄ±rma)
- Stop words kaldÄ±rÄ±lÄ±r
- Tokenization iÅŸlemi gerÃ§ekleÅŸtirilir
- Maksimum uzunluk sÄ±nÄ±rlamalarÄ± uygulanÄ±r

### 4. Model EÄŸitimi
- 500 Ã¶rnek ile eÄŸitim gerÃ§ekleÅŸtirilir
- 3 epoch boyunca eÄŸitim
- Validation seti ile performans izleme

### 5. DeÄŸerlendirme
- Test seti Ã¼zerinde Ã¶zetleme
- ROUGE metrikleri hesaplama
- SonuÃ§larÄ±n JSON formatÄ±nda kaydedilmesi

## ğŸ“ˆ Model Parametreleri

- **Model**: T5-small
- **Maksimum giriÅŸ uzunluÄŸu**: 512 token
- **Maksimum hedef uzunluÄŸu**: 128 token
- **EÄŸitim epoch sayÄ±sÄ±**: 3
- **Batch size**: 2
- **Learning rate**: 3e-5

## ğŸ“Š Veri Seti Bilgileri

- **Kaynak**: CNN/DailyMail veri seti
- **EÄŸitim Ã¶rnekleri**: 500 (ilk 500 Ã¶rnek)
- **Validation Ã¶rnekleri**: 50
- **Test Ã¶rnekleri**: 5
- **GiriÅŸ**: Haber makaleleri
- **Hedef**: Makale Ã¶zetleri

## ğŸ¯ SonuÃ§lar ve DeÄŸerlendirme

Proje baÅŸarÄ±yla tamamlanmÄ±ÅŸ ve aÅŸaÄŸÄ±daki sonuÃ§lar elde edilmiÅŸtir:

- Model eÄŸitimi tamamlandÄ±
- ROUGE skorlarÄ± hesaplandÄ±
- Ã–rnek Ã¶zetler Ã¼retildi
- SonuÃ§lar JSON dosyasÄ±na kaydedildi

### ROUGE SkorlarÄ± Analizi:
- **ROUGE-1 (0.3224)**: Tek kelime Ã¶rtÃ¼ÅŸmesi - makul seviyede
- **ROUGE-2 (0.0715)**: Ä°ki kelime Ã¶rtÃ¼ÅŸmesi - geliÅŸtirilebilir
- **ROUGE-L (0.2239)**: En uzun ortak alt dizi - kabul edilebilir

## ğŸ”® Gelecek GeliÅŸtirmeler

- Daha bÃ¼yÃ¼k veri seti kullanÄ±mÄ±
- FarklÄ± model mimarileri deneme
- Hiperparametre optimizasyonu
- Daha uzun eÄŸitim sÃ¼resi
- TÃ¼rkÃ§e veri seti ile deneme

## ğŸ“ Lisans

Bu proje eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir.

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

Bu proje NLP dersi kapsamÄ±nda geliÅŸtirilmiÅŸtir.

---

**Not**: Bu proje, doÄŸal dil iÅŸleme alanÄ±nda Ã¶zetleme gÃ¶revlerinin nasÄ±l gerÃ§ekleÅŸtirileceÄŸini gÃ¶stermek amacÄ±yla hazÄ±rlanmÄ±ÅŸtÄ±r. 

